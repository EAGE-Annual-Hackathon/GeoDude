{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT Loading Multiple PDF using LLama Index and Llama collectors"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, rather than training a model from scratch, we can leverage the benefits of using a pre-trained model and enhance its knowledge by extracting information from a PDF using Llama collectors and the Llama index. This approach, known as context learning, allows us to reduce resource consumption while creating a customized model specifically designed for geoscience."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will use the LLM from open ai, therefore we need to have an open AI key. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['OPENAI_API_KEY'] = \"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\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\" \n",
    "\n",
    "from pathlib import Path #needed for the pdf connector\n",
    "from llama_index import download_loader\n",
    "from llama_index import SimpleDirectoryReader # Simple reader from txt\n",
    "\n",
    "from llama_index import (\n",
    "    GPTVectorStoreIndex,\n",
    "    GPTEmptyIndex,\n",
    "    GPTTreeIndex,\n",
    "    GPTListIndex,\n",
    "    SimpleDirectoryReader,\n",
    "    ServiceContext,\n",
    "    StorageContext,\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From Context\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pdf reader from llama connectors"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the pdf file to introduce our dataset and create the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading data for index\n",
    "loader = SimpleDirectoryReader('./data_test') #, recursive=True, exclude_hidden=True)\n",
    "documents = loader.load_data()\n",
    "\n",
    "# new_index = GPTVectorStoreIndex.from_documents(documents)\n",
    "new_index = GPTListIndex.from_documents(documents)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the query and the response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mentioned in the context information?\n",
      "\n",
      "1. Deep Learning to replace or augment model-based seismic inversion?\n",
      "2. Joint Inversion and Segmentation of the 4D Sleipner Seismic Dataset\n",
      "3. Plug and Play Post-Stack Seismic Inversion with CNN-Based Denoisers\n",
      "4. Diffraction Imaging of Faults, Basement Fractures and Stratigraphy in the Southern Malay Basin\n"
     ]
    }
   ],
   "source": [
    "# query with embed_model specified\n",
    "query_engine = new_index.as_query_engine(response_mode='tree_summarize',\n",
    "    verbose=False\n",
    ")\n",
    "response = query_engine.query(\"What are the titles of the documents\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The documents are about the use of deep learning for seismic inversion and joint inversion and segmentation of 4D seismic datasets. The first document discusses how deep learning can be used to replace or augment model-based seismic inversion, while the second document discusses how joint inversion and segmentation can be used to analyze the 4D Sleipner seismic dataset. The third document discusses a workflow of combined diffraction imaging and customization to interpretation for injectite and fractured basement targets.\n"
     ]
    }
   ],
   "source": [
    "# query with embed_model specified\n",
    "query_engine = new_index.as_query_engine(response_mode='tree_summarize'\n",
    ")\n",
    "response_2 = query_engine.query(\"What are the documents about\")\n",
    "print(response_2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geodude",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "caed2004f21303f7cc20ad6839fc73b016897941130ed587ced8f2b4def15e03"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
