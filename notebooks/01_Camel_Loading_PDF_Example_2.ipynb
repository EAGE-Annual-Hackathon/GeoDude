{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Camel 5b Loading PDF using LLama Index and Llama collectors (HugginFace Embeddings)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, rather than training a model from scratch, we can leverage the benefits of using a pre-trained model and enhance its knowledge by extracting information from a PDF using Llama collectors and the Llama index. This approach, known as context learning, allows us to reduce resource consumption while creating a customized model specifically designed for geoscience."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will use the LLM from open ai, therefore we need to have an open AI key. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['OPENAI_API_KEY'] = \"insert your openai key \"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\" \n",
    "\n",
    "\n",
    "from llama_index import GPTListIndex, SimpleDirectoryReader\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from llama_index import LangchainEmbedding, ServiceContext\n",
    "from llama_index.llm_predictor import HuggingFaceLLMPredictor\n",
    "from llama_index import GPTVectorStoreIndex, GPTEmptyIndex\n",
    "\n",
    "from pathlib import Path #needed for the pdf connector\n",
    "from llama_index import download_loader\n",
    "\n",
    "# setup prompts - specific to StableLM\n",
    "from llama_index.prompts.prompts import SimpleInputPrompt\n",
    "\n",
    "import torch\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will begin by posing a \"geoscience question\" in order to establish a benchmark. This step is intended to gauge the pretrained model's ability to provide an answer without any prior knowledge or context regarding a specific problem that will be introduced later on."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Model with HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will wrap the default prompts that are internal to llama-index\n",
    "# taken from https://huggingface.co/Writer/camel-5b-hf\n",
    "query_wrapper_prompt = SimpleInputPrompt(\n",
    "    \"Below is an instruction that describes a task. \"\n",
    "    \"Write a response that appropriately completes the request.\\n\\n\"\n",
    "    \"### Instruction:\\n{query_str}\\n\\n### Response:\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2801babbb5c445fb8eb4e45b56ef5a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hf_predictor = HuggingFaceLLMPredictor(\n",
    "    max_input_size=2048, \n",
    "    max_new_tokens=256,\n",
    "    # temperature=0.25,\n",
    "    # do_sample=False,\n",
    "    query_wrapper_prompt=query_wrapper_prompt,\n",
    "    tokenizer_name=\"Writer/camel-5b-hf\",\n",
    "    model_name=\"Writer/camel-5b-hf\",\n",
    "    device_map=\"auto\",\n",
    "    tokenizer_kwargs={\"max_length\": 2048},\n",
    "    # model_kwargs={\"torch_dtype\": torch.bfloat16}\n",
    "    model_kwargs={\"torch_dtype\": torch.float16},\n",
    ")\n",
    "\n",
    "embed_model = LangchainEmbedding(HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\"))\n",
    "\n",
    "service_context = ServiceContext.from_defaults(chunk_size_limit=512, llm_predictor=hf_predictor, embed_model=embed_model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this we will create an empty index, it will allow us to get an answer directly from the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build empty index\n",
    "empty_index = GPTEmptyIndex(service_context=service_context)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the query, and obtaining the response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model-based seismic invasion is a predictive method that uses mathematical models to simulate the behavior of a subsurface structure under seismic loading. These models are based on the underlying rock properties, such as elasticity, density, and fault geometry. The models are calibrated using historical data and then used to predict the likelihood of seismic events, such as ground shaking or ground deformation.\n",
      "\n",
      "Data-driven seismic invasion, on the other hand, involves collecting and analyzing large amounts of seismic data from real-world events to identify patterns and relationships between the seismic signals and the subsurface structure. This data-driven approach relies on the interpretation of the seismic data to identify potential vulnerabilities and risks to human and infrastructure safety.\n"
     ]
    }
   ],
   "source": [
    "query_engine = empty_index.as_query_engine(\n",
    "    response_mode='generation'\n",
    ")\n",
    "response_benchmark = query_engine.query(\n",
    "    \"What is the difference between model-based and data-driven seismic invesion?\",\n",
    ")\n",
    "print(response_benchmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Supervised Learning is better used for post-stack seismic inversion when the data is clean and well-labeled, with clear boundaries between the ground and the subsurface structures.\n"
     ]
    }
   ],
   "source": [
    "query_engine = empty_index.as_query_engine(\n",
    "    response_mode='generation'\n",
    ")\n",
    "response_benchmark_2 = query_engine.query(\n",
    "    \"When is better to use Supervised Learning for post-stack seismic inversion?\",\n",
    ")\n",
    "print(response_benchmark_2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this we obtained the benchamark answer. Now, we will proceed to inject the knowledge of a pdf (EAGE abstract)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From Context\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pdf reader from llama connectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "CJKPDFReader = download_loader(\"CJKPDFReader\")\n",
    "loader = CJKPDFReader()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the pdf file to introduce our dataset and create the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = loader.load_data(file=Path('data_test/158.pdf'))\n",
    "index = GPTVectorStoreIndex.from_documents(documents,service_context=service_context)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the query and the response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (937 > 512). Running this sequence through the model will result in indexing errors\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model-based inversion relies on a mathematical model to invert seismic data, while data-driven inversion uses training data to learn the relationship between acoustic impedance and seismic data.\n"
     ]
    }
   ],
   "source": [
    "query_engine = index.as_query_engine()\n",
    "response_context = query_engine.query(\"What is the difference between model-based and data-driven seismic invesion?\")\n",
    "print(response_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When the data is scarce or the background model is unavailable, using Supervised Learning for post-stack seismic inversion is better as it requires no train-\n",
      "ing data and can handle noisy data effectively.\n"
     ]
    }
   ],
   "source": [
    "query_engine = index.as_query_engine()\n",
    "response_context_2 = query_engine.query(\"When is better to use Supervised Learning for post-stack seismic inversion?\")\n",
    "print(response_context_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asking about the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The document discusses the application of PnP priors in seismic inversion, focusing on the use of learned denoising neural networks as a regularizer in solving inverse problems. It compares model-based and data-driven methods, highlighting the advantages of supervised regularization, and provides numerical examples.\n"
     ]
    }
   ],
   "source": [
    "query_engine = index.as_query_engine(response_mode=\"compact\")\n",
    "response_context_4 = query_engine.query(\"give me a summary of the document\")\n",
    "print(response_context_4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geodude",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "caed2004f21303f7cc20ad6839fc73b016897941130ed587ced8f2b4def15e03"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
