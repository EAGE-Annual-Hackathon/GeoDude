{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Camel 5b Loading PDF using LLama Index and Llama collectors (HugginFace Embeddings)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, rather than training a model from scratch, we can leverage the benefits of using a pre-trained model and enhance its knowledge by extracting information from a PDF using Llama collectors and the Llama index. This approach, known as context learning, allows us to reduce resource consumption while creating a customized model specifically designed for geoscience."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will use the LLM from open ai, therefore we need to have an open AI key. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['OPENAI_API_KEY'] = \"insert your openai key \"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\" \n",
    "\n",
    "\n",
    "from llama_index import GPTListIndex, SimpleDirectoryReader\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from llama_index import LangchainEmbedding, ServiceContext\n",
    "from llama_index.llm_predictor import HuggingFaceLLMPredictor\n",
    "from llama_index import GPTVectorStoreIndex, GPTEmptyIndex\n",
    "\n",
    "from pathlib import Path #needed for the pdf connector\n",
    "from llama_index import download_loader\n",
    "\n",
    "# setup prompts - specific to StableLM\n",
    "from llama_index.prompts.prompts import SimpleInputPrompt\n",
    "\n",
    "import torch\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will begin by posing a \"geoscience question\" in order to establish a benchmark. This step is intended to gauge the pretrained model's ability to provide an answer without any prior knowledge or context regarding a specific problem that will be introduced later on."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Model with HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will wrap the default prompts that are internal to llama-index\n",
    "# taken from https://huggingface.co/Writer/camel-5b-hf\n",
    "query_wrapper_prompt = SimpleInputPrompt(\n",
    "    \"Below is an instruction that describes a task. \"\n",
    "    \"Write a response that appropriately completes the request.\\n\\n\"\n",
    "    \"### Instruction:\\n{query_str}\\n\\n### Response:\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5838abbb41d468bb8c9d246857ecbe5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hf_predictor = HuggingFaceLLMPredictor(\n",
    "    max_input_size=2048, \n",
    "    max_new_tokens=256,\n",
    "    # temperature=0.25,\n",
    "    # do_sample=False,\n",
    "    query_wrapper_prompt=query_wrapper_prompt,\n",
    "    tokenizer_name=\"Writer/camel-5b-hf\",\n",
    "    model_name=\"Writer/camel-5b-hf\",\n",
    "    device_map=\"auto\",\n",
    "    tokenizer_kwargs={\"max_length\": 2048},\n",
    "    # model_kwargs={\"torch_dtype\": torch.bfloat16}\n",
    "    model_kwargs={\"torch_dtype\": torch.float16},\n",
    ")\n",
    "\n",
    "embed_model = LangchainEmbedding(HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\"))\n",
    "\n",
    "service_context = ServiceContext.from_defaults(chunk_size_limit=512, llm_predictor=hf_predictor, embed_model=embed_model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this we will create an empty index, it will allow us to get an answer directly from the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build empty index\n",
    "empty_index = GPTEmptyIndex(service_context=service_context)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the query, and obtaining the response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation on 4D seismic inversion allows for the analysis of subsurface structures and properties by dividing the data into smaller subsets or segments. This improves the accuracy and resolution of the inversion results, allowing for better understanding of the subsurface structure, composition, and fluid content.\n"
     ]
    }
   ],
   "source": [
    "query_engine = empty_index.as_query_engine(\n",
    "    response_mode='generation'\n",
    ")\n",
    "response_benchmark = query_engine.query(\n",
    "    \"What is the benefit of using segmentation on 4D seismic inversion?\",\n",
    ")\n",
    "print(response_benchmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regularization techniques for post-stack seismic inversion include Tikhonov regularization, L1-regularization, and L2-regularization. Tikhonov regularization is simple and effective, but may lead to overfitting. L1-regularization is suitable for problems with a large number of parameters, but may result in noisy solutions. L2-regularization is more robust and can handle both large and small parameter values, but it may lead to underfitting. It's recommended to use a combination of techniques, such as L1-regularization with Tikhonov regularization for robustness and L2-regularization for better accuracy.\n"
     ]
    }
   ],
   "source": [
    "query_engine = empty_index.as_query_engine(\n",
    "    response_mode='generation'\n",
    ")\n",
    "response_benchmark_2 = query_engine.query(\n",
    "    \"What type of regularization should I use for post-stack seismic inversion?\",\n",
    ")\n",
    "print(response_benchmark_2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this we obtained the benchamark answer. Now, we will proceed to inject the knowledge of a pdf (EAGE abstract)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From Context\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pdf reader from llama connectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "CJKPDFReader = download_loader(\"CJKPDFReader\")\n",
    "loader = CJKPDFReader()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the pdf file to introduce our dataset and create the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = loader.load_data(file=Path('data_test/315.pdf'))\n",
    "index = GPTVectorStoreIndex.from_documents(documents, service_context=service_context)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the query and the response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (964 > 512). Running this sequence through the model will result in indexing errors\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation enhances the interpretation of seismic data by dividing the subsurface into distinct layers, allowing for more accurate reservoir property estimation and better risk assessment.\n"
     ]
    }
   ],
   "source": [
    "query_engine = index.as_query_engine()\n",
    "response_context = query_engine.query(\"What is the benefit of using segmentation on seismic inversion?\")\n",
    "print(response_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For post-stack seismic inversion, you should use the 4D JIS algorithm (Ravasi and Birnie, 2022; Romero et al., 2022).\n"
     ]
    }
   ],
   "source": [
    "query_engine = index.as_query_engine()\n",
    "response_context_2 = query_engine.query(\"What type of regularization should I use for post-stack seismic inversion?\")\n",
    "print(response_context_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asking about the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 4D joint inversion method is novel as it combines the advantages of 4D seismic data analysis with the capability of\n",
      "segmenting and inversion of 4D seismic data, leading to improved subsurface model resolution and reduced noise in the\n",
      "inverted difference.\n"
     ]
    }
   ],
   "source": [
    "query_engine = index.as_query_engine(response_mode=\"compact\")\n",
    "response_context_3 = query_engine.query(\"What is the novelty of 4D joint inversion\")\n",
    "print(response_context_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The document is a summary of the Sleipner dataset, including the well-analysis workflow, well-to-seismic tie, and time-shift distribution.\n"
     ]
    }
   ],
   "source": [
    "query_engine = index.as_query_engine(response_mode=\"compact\")\n",
    "response_context_4 = query_engine.query(\"give me a summary of the document\")\n",
    "print(response_context_4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geodude",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "caed2004f21303f7cc20ad6839fc73b016897941130ed587ced8f2b4def15e03"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
